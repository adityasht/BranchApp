from huggingface_hub import InferenceClient
import os

# Ensure you have the necessary packages installed
# pip install huggingface-hub transformers

# Read database password from pass.txt file
def get_token():
    with open(os.path.join(os.path.dirname(__file__), 'hf_token.txt'), 'r') as f:
        return f.read().strip()

API_TOKEN = get_token()

def get_interests_recommender(interests):
    interests = [interest.lower().strip().replace(" ", "_") for interest in interests]
    # Create the client with the correct model
    client = InferenceClient(
        model="mistralai/Mistral-7B-Instruct-v0.3",
        token=API_TOKEN,
    )

    # Prepare the prompt for the model
    prompt = (
        "Given the following interests: %s, suggest 5 similar interests using 1 word each."
        % ', '.join(interests)
    )

    # Generate text using the InferenceClient
    response = client.text_generation(
        prompt,
        max_new_tokens=32,  # Adjust the number of tokens as needed
        temperature=0.1,    # Adjust the randomness of the output
    )

    # Print the response generated by the model
    print(response)
    # Extracting and parsing the response
    generated_text = response.strip().split('\n')
    # Remove numeric prefixes and clean up the text
    modified_list = [s[3:] for s in generated_text]
    print(modified_list)
    return modified_list[0:5]

def find_tags(eventname, eventdesc):
    # Create the client with the correct model
    client = InferenceClient(
        model="mistralai/Mistral-7B-Instruct-v0.3",
        token="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",
    )

    # Prepare the prompt for the model
    prompt = (
        "Given the event name and description: %s, suggest 3 tags that are each 1 word."
        % ', '.join(interests)
    )

    # Generate text using the InferenceClient
    response = client.text_generation(
        prompt,
        max_new_tokens=64,  # Adjust the number of tokens as needed
        temperature=0.1,    # Adjust the randomness of the output
    )

    # Print the response generated by the model
    print(response)
    # Extracting and parsing the response
    generated_text = response.strip().split('\n')
    # Remove numeric prefixes and clean up the text
    modified_list = [s[3:] for s in generated_text]
    print(modified_list)
    return modified_list[0:4]


if __name__ == "__main__":
    interests = ["machine learning", "data science", "python"]
    get_interests_recommender(interests)
    find_tags("Hackathon", "A coding competition for developers.")